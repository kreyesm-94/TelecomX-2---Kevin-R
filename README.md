# TelecomX-2---Kevin-R

# *Curso de estadistica con Machine Learning* #

üéØ Misi√≥n

Tu nueva misi√≥n es desarrollar modelos predictivos capaces de prever qu√© clientes tienen mayor probabilidad de cancelar sus servicios.
La empresa quiere anticiparse al problema de la cancelaci√≥n, y te corresponde a ti construir un pipeline robusto para esta etapa inicial de modelado.


üß† Objetivos del Desaf√≠o

Preparar los datos para el modelado (tratamiento, codificaci√≥n, normalizaci√≥n).
Realizar an√°lisis de correlaci√≥n y selecci√≥n de variables.
Entrenar dos o m√°s modelos de clasificaci√≥n.
Evaluar el rendimiento de los modelos con m√©tricas.
Interpretar los resultados, incluyendo la importancia de las variables.
Crear una conclusi√≥n estrat√©gica se√±alando los principales factores que influyen en la cancelaci√≥n.


üß∞ Habilidades que se van a pr√°cticar en este TelecomX 2

‚úÖ Preprocesamiento de datos para Machine Learning

‚úÖ Construcci√≥n y evaluaci√≥n de modelos predictivos

‚úÖ Interpretaci√≥n de resultados y entrega de insights

‚úÖ Comunicaci√≥n t√©cnica con enfoque estrat√©gico


# *Creaci√≥n de repositorio en GitHub para almacenar el an√°lisis* #

¬°Organizar tu proyecto desde el principio facilita el desarrollo y garantiza buenas pr√°cticas en el control de versiones! üöÄ
- Repositorio Kevin Reyes / Nombre: TELECOMx-2 Kevin R

# *Extracci√≥n del Archivo Tratado* #

En el proyecto de TelecomX-1 se realizo un an√°lisis exploratorio de los datos, logrando identificar insight importantes para la empresa y para la toma de decisiones. Para este proyecto se trabajar√≠a con el archivo final que se obtuvo del TelecomX-1, sera la base e insumo necesario para poder llevar acabo el an√°lisis deseado en el TelecomX-2

- Creaci√≥n de nuevo cuaderno de Colaboraty Colab
- Carga de archivo CSV / "df_final_kev_TelecomX 2

# *Eliminaci√≥n de columnas innecesarias y tratamiendo de columnas* #
En todo proyecto es necesario realizar un an√°lisis generar de la data con la que contamos, esto para asegurar que solo almacenemos la informaci√≥n necesaria. Si es necesario eliminar columnas o filas poder hacerlo y si es necesario realizar el tratamiento de columnas tambi√©n poder hacerlo

- Eliminamos la fila de "customer ID"
- Ejecutamos c√≥digo para validar la correlaci√≥n de cuentas y correlaci√≥n del tenere total

# *Ejecusi√≥n del Encoding* #
Nos permite transforma las variables categ√≥ricas a formato num√©rico para hacerlas compatibles con los algoritmos de machine learning.

- Importamos bibliotecas OneHotEncoder / ColumnTransformer
- Transformaci√≥n de variables a num√©ros

# *Ejecusi√≥n de la verificaci√≥n de la proporci√≥n de cancelaci√≥n (Churn)* #
Calcula la proporci√≥n de clientes que cancelaron en relaci√≥n con los que permanecieron activos. Eval√∫a si existe un desbalance entre las clases, ya que esto puede impactar en los modelos predictivos y en el an√°lisis de los resultados
Este paso es muy importante antes de entrenar, porque si la proporci√≥n est√° muy desbalanceada, el modelo puede aprender a ‚Äúpredecir siempre la clase mayoritaria‚Äù y aun as√≠ tener un accuracy alto pero in√∫til.

# *Balanceo de clases* #
Es necesario aplicar t√©cnicas de balanceo como undersampling o oversampling. En situaciones de fuerte desbalanceo, herramientas como SMOTE pueden ser √∫tiles para generar ejemplos sint√©ticos de la clase minoritaria.
Debemos asegurarnos de que todas las columnas sean num√©ricas.

# *Estandarizaci√≥n* #
La estandarizaci√≥n eval√∫a la necesidad de normalizar o estandarizar los datos, seg√∫n los modelos que se aplicar√°n. Modelos basados en distancia, como KNN, SVM, Regresi√≥n Log√≠stica y Redes Neuronales, requieren este preprocesamiento. Por otro lado, modelos basados en √°rboles, como Decision Tree, Random Forest y XGBoost, no son sensibles a la escala de los datos.

# *An√°lisis de correlaci√≥n* #
Visualiza la matriz de correlaci√≥n para identificar relaciones entre las variables num√©ricas. Presta especial atenci√≥n a las variables que muestran una mayor correlaci√≥n con la cancelaci√≥n, ya que estas pueden ser fuertes candidatas para el modelo predictivo.

Ya que transformamos las variables categ√≥ricas en num√©ricas, podemos calcular y visualizar la matriz de correlaci√≥n para ver qu√© tan relacionadas est√°n con la cancelaci√≥n

# *An√°lisis dirigido* #
Variables especificas que se relacionan directamente con el;

- Tiempo de contrato √ó Cancelaci√≥n
- Gasto total √ó Cancelaci√≥n
Adicional se agregaron dos opciones m√°s;
- Gasto mensual X Cancelaci√≥n (Dato extra)
- Contrato (tipo) X Cancelaci√≥n (Dato extra)

# *Separaci√≥n de datos* #

Se devide el conjunto de datos en entrenamiento y prueba para evaluar el rendimiento del modelo. Una divisi√≥n com√∫n es 70% para entrenamiento y 30% para prueba, o 80/20, dependiendo del tama√±o de la base de datos.

# *Creaci√≥n de modelos* #
Se crearon dos modelos;

Modelo log√≠stico: Se aplico la normalizaci√≥n

Random forest: No se aplico normalizaci√≥n

# **Justificaci√≥n del preprocesamiento** #

Para la Regresi√≥n Log√≠stica, aplicamos normalizaci√≥n porque es un modelo basado en optimizaci√≥n matem√°tica (gradiente descendente). Si no escalamos, variables con rangos grandes podr√≠an dominar el entrenamiento.

Para Random Forest, no aplicamos normalizaci√≥n porque los √°rboles se basan en umbrales de partici√≥n (ej. ‚Äúedad < 30‚Äù), lo que hace irrelevante la escala de la variable.

Realizmos una comparaci√≥n de resultados con los datos extraidos;
a Regresi√≥n Log√≠stica obtuvo una accuracy de ~0.85 y un buen recall en la clase positiva (clientes que cancelan).

El Random Forest super√≥ ligeramente con accuracy de ~0.87, mostrando mayor balance entre precisi√≥n y recall.

# **Evaluaci√≥n de modelos** #

Realizar una evaluaci√≥n para los diferentes modelos aplicados en el an√°lisis ayuda a identificar que metricas importantes para el negocio se mueven a favor o en contra, de esta manera se puede preveenir o mejorar de alguna manera antes de que suceda la cancelaci√≥n.


_Regresi√≥n Log√≠stica_
Predijo bien la mayor√≠a de cancelaciones (recall = 0.98).
Fall√≥ m√°s en clientes que no cancelan, generando falsos positivos (predijo cancelaci√≥n cuando no era).

_Random Forest_
M√°s equilibrado entre clases.
No favorece en exceso a los clientes que cancelan o los que permanecen.


Se realizo un an√°lisis de comparaci√≥n determinando que el modelo que presento mejor rendimiendo es el Random Forest (accuracy 0.87), teniendo una mejor interpretaci√≥n de los datos y balance entre las descripciones de la base.

# **Ejecusi√≥n de curva de ROC** #

Ambos modelos tienen curvas muy por encima de la l√≠nea aleatoria, indicando alta capacidad de clasificaci√≥n.
Conclusi√≥n final:
- La Regresi√≥n Log√≠stica es el modelo ganador en este caso:
- Tiene mejor AUC (0.98).
- Es m√°s simple de implementar e interpretar.
- Generaliza mejor en este dataset que Random Forest.

# **An√°lisis de la Importancia de las Variables** #

Despu√©s de elegir los modelos es importante que se realice el an√°lisis de las variables m√°s relevantes para la predicci√≥n de la cancelaci√≥n.
Se realizo una gr√°fica con las 15 variables mas significativas de la data, dato importante para determinar en que descripci√≥n enfocalizarse.


# **Conclusi√≥n** #

Se brinda una conclusi√≥n detallada analizando las varibles establecidas y modelos utilizados, de esta manera se concluye que el modelo que mejor predice es el Random Forest, sin descartar que el modelo de Regresi√≥n Log√≠stica, permite no solo predecir cancelaciones con un 87% de exactitud, si no tambi√©n entender que tipo de factores las impulsan.

Adicional se brinda una recomendaci√≥n general de estrateg√≠as de permanecia que podr√≠an ayudar a la empresa con la retenci√≥n de clientes.
